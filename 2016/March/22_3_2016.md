###To Do from Tuesday March 22, 2016

+ Add MuTect2 into Loeb Snakemake workflow
+ Finish MarkDuplicateWithMateCigar on the TruSeq sample (**DONE**)
+ Check MuTect2 output for 100% Tumor Colo Sample, and create ROC curve.
    + Work on code to generate the FM/FP plots.
    + Create code to generate ROC curves overall
+ Work on GCC on the Slurm cluster
+ Run cutadapt prior to barcode collapse with BMFtools, and compare to run where cutadapt comes after collapse.
+ Look into PandaSeq or similar, how could/should we utilize overlapping reads?
+ Run MarkDuplicatesWithMateCigar on Loeb data, preferably the 100% tumor, same as the TruSeq run.  Be sure ot use a sample that is run through cutadapt first.

##Mutect2
    /home/brett/projects/BMFTools_Devel/Somatic_Analysis/HiSeq_Loeb_Colo_Run2_wCA/5_100Colo_10N11N_LB
    /home/brett/projects/BMFTools_Devel/Somatic_Analysis/Colo829_Strelka_Results

output form MuTect2 run on 100% colo with cutadapt (HiSeq_Loeb_Run2)

    INFO  16:17:37,438 VectorLoglessPairHMM - Time spent in setup for JNI call : 0.22744434100000002
    INFO  16:17:37,438 PairHMM - Total compute time in PairHMM computeLikelihoods() : 1461.377182057
    INFO  16:17:37,438 MuTect2 - Ran local assembly on 102 active regions
    INFO  16:17:37,502 ProgressMeter -            done         312862.0    28.3 m           90.6 m      100.0%    28.3 m       0.0 s
    INFO  16:17:37,503 ProgressMeter - Total runtime 1699.97 secs, 28.33 min, 0.47 hours
    INFO  16:17:37,503 MicroScheduler - 105429 reads were filtered out during the traversal out of approximately 547847 total reads (19.24%)
    INFO  16:17:37,503 MicroScheduler -   -> 0 reads (0.00% of total) failing BadCigarFilter
    INFO  16:17:37,503 MicroScheduler -   -> 0 reads (0.00% of total) failing DuplicateReadFilter
    INFO  16:17:37,504 MicroScheduler -   -> 52774 reads (9.63% of total) failing FailsVendorQualityCheckFilter
    INFO  16:17:37,504 MicroScheduler -   -> 0 reads (0.00% of total) failing MalformedReadFilter
    INFO  16:17:37,504 MicroScheduler -   -> 0 reads (0.00% of total) failing MappingQualityUnavailableFilter
    INFO  16:17:37,504 MicroScheduler -   -> 0 reads (0.00% of total) failing NotPrimaryAlignmentFilter
    INFO  16:17:37,504 MicroScheduler -   -> 52655 reads (9.61% of total) failing UnmappedReadFilter
    INFO  16:17:38,730 GATKRunReport - Uploaded run statistics report to AWS S3

Ran with the new bed file.  This analysis recovered **172 variants** in the capture region, of these **13 are annotated with "PASS"** from MuTect2.

Interesting, looking at the run statistics, we do lose about 20% of the reads, 10% to umapped and 10% to the quality fail filter (which can fail things for a variety of reasons, including stuff from BMFtools itself).  That follows what David said about 20% of stuff just not making it through.  In the end we used only ~450,000 reads after collapse.

This translates in the effective coverage by:

(number of reads * readlength) / total size of bed region

I get the total size of the bed regions using the hack:

    cat file.bed | awk -F'\t' 'BEGIN{SUM=0}{ SUM+=$3-$2 }END{print SUM}'

which finds a total length of 28,787kb

so plugging that into the equation above

    ((547847-105429)\*121)/28787 = 1859.609

which falls into our range of expected number of molecules.  Good.

Here are the variants which pass

    1	11169711	.	G	T	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=73.00;TLOD=6.33	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:320,3:0.012:0:3:0.00:12472,120:174:146	0/0:301,0:0.00:0:0:.:11732,0:142:159
    1	11174887	.	A	T	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=194.69;TLOD=7.75	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:358,8:0.017:5:3:0.375:14080,280:173:185	0/0:744,1:1.511e-03:0:1:1.00:29286,40:279:465
    2	29445272	.	C	A	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=112.61;TLOD=9.86	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:701,6:9.677e-03:4:2:0.333:27171,238:445:256	0/0:464,0:0.00:0:0:.:17782,0:229:235
    2	29447197	.	C	G	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=116.56;TLOD=7.34	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:473,6:0.015:3:3:0.500:18366,238:207:266	0/0:485,0:0.00:0:0:.:18915,0:243:242
    5	83402558	.	TG	T	.	PASS	ECNT=2;HCNT=1;MAX_ED=1;MIN_ED=1;NLOD=77.33;RPA=2,1;RU=G;STR;TLOD=6.34	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:463,12:0.024:10:2:.:18148,476:338:125	0/0:326,0:0.00:0:0:.:12716,0:175:151
    7	55224391	.	A	T	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=181.31;TLOD=7.36	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:615,4:3.953e-03:2:2:0.500:23810,160:314:301	0/0:686,1:8.084e-04:0:1:1.00:26600,40:183:503
    7	140453136	rs113488022	A	T	.	PASS	DB;ECNT=1;HCNT=30;MAX_ED=.;MIN_ED=.;NLOD=82.82;TLOD=1633.39	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:245,549:0.518:272:277:0.505:9556,21246:140:105	0/0:372,0:0.00:0:0:.:14561,0:187:185
    11	55418737	.	C	T	.	PASS	ECNT=1;HCNT=44;MAX_ED=.;MIN_ED=.;NLOD=38.64;TLOD=1150.29	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:1,332:0.996:146:186:0.560:13,12772:1:0	0/0:183,1:0.014:1:0:0.00:7106,40:99:84
    11	120776055	.	CT	C	.	PASS	ECNT=1;HCNT=43;MAX_ED=.;MIN_ED=.;NLOD=175.47;TLOD=1126.92	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:5,358:0.990:173:185:.:165,13653:2:3	0/0:651,0:0.00:0:0:.:25334,0:278:373
    12	25378596	.	T	A	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=79.33;TLOD=7.33	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:384,4:0.013:0:4:0.00:15012,158:178:206	0/0:340,0:0.00:0:0:.:13257,0:173:167
    12	75444892	.	A	G	.	PASS	ECNT=1;HCNT=36;MAX_ED=.;MIN_ED=.;NLOD=69.90;TLOD=704.77	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:140,242:0.458:112:130:0.537:5488,9488:82:58	0/0:309,0:0.00:0:0:.:12017,0:176:133
    15	66727549	.	C	A	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=200.40;TLOD=6.39	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:309,3:0.012:1:2:0.667:12077,120:136:173	0/0:750,0:0.00:0:0:.:29129,0:335:415
    17	7576903	.	A	T	.	PASS	ECNT=1;HCNT=1;MAX_ED=.;MIN_ED=.;NLOD=125.20;TLOD=9.29	GT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:QSS:REF_F1R2:REF_F2R1	0/1:537,6:0.013:4:2:0.333:20370,225:261:276	0/0:527,0:2.387e-03:0:0:.:20136,0:255:272

In order to create a truth set for the calls, I need to combine the calls from the Strelka paper, which we should be able to recover here.  I culled the extra target probes from that set for those which had the largest discordance in allele counts between the tumor and Normal.  I will combine them using GATK's CatVariants tool

    java -jar ~/bin/GenomeAnalysisTK.jar \
        -T CombineVariants \
        -R ~/projects/Reference_Genomes/hg19/hg19.fa \
        -V strelka.passed.coding.somatic.indels.vcf \
        -V strelka.passed.missense.somatic.snvs.vcf \
        -V strelka.passed.nonsense.somatic.snvs.vcf \
        -o strelka.passed.coding.somatic.vcf \
        --genotypemergeoption UNSORTED

Now I have to remove the chr from in front of each chromosome (stupid hg19)

    sed 's/chr//g' strelka.passed.coding.somatic.vcf > strelka.passed.coding.somatic.noCHR.vcf

Then I find the expected variants found in the Strelka calls that should also be found in our calls using bedtools

    bedtools intersect -header -a strelka.passed.coding.somatic.noCHR.vcf -b ~/projects/BMFTools_Devel/Panel/re_extend_panel/ctDNA_V2_probes_with_colo829_dopes.bed > ctDNA_V2_Colo829dopes_StrelkaSomaticCalls.vcf

Now the file "ctDNA_V2_Colo829dopes_StrelkaSomaticCalls.vcf" is my "truth" set for calls from MuTect2.  One obvious problem is that MuTect2 may actually be more sensitive than Strelka, so I have to consider FPs from MuTect2 to be potentially true, however, I should be able to observe all of these variants in the callset.

Following on that, it appears that MuTect2 might actually just be a better caller.  variants in the capture that are annotated PASS in the Strelka data are all present in the Mutect data, and a number of them are also annotated PASS, importantly including BRAFV600E
(7:140453136).  However, for a number of other calls, MuTect has good reasons to be skeptical of the variants, including clustered events and gc region extensions.  I'll need to do a more careful comparison so see what's going on.

to start considering how to look at some of these variants, I'm going to use BMFtools vet method.  

    bmftools vet -b ~/projects/BMFTools_Devel/Panel/re_extend_panel/ctDNA_V2_probes_with_colo829_dopes.bed -c 1 -s 2 --skip-recommended --skip-qcfail 8_100BL_10N11N_LB.bcf ../BAMs/5_100Colo_10N11N_LB_rescued.realigned.bam > 8_100BL_10N11N_LB.vetted.bcf

This will just give me an idea of what variants are successfully passing basic barcode meta-analysis filters.

##Picard MarkDuplicatesWithMateCigar on TruSeq data
    /uufs/chpc.utah.edu/common/home/arup-storage1/u0521163/ctDNA_Data/no_barcodes/TruSeq

Strange bug with picard, I ran it twice, one removing duplicates and once just marking them.  The run that just marked them failed again.  Suggesting the BAM still was not coordinate sorted (I sorted it using samtools).  The second run, which used the REMOVE_DUPLICATES=true flag, finished quickly.

    INFO    2016-03-22 10:18:13     MarkDuplicatesWithMateCigar     Processed 6783276 records
    INFO    2016-03-22 10:18:13     MarkDuplicatesWithMateCigar     Found 0 records with no mate cigar optional tag.
    INFO    2016-03-22 10:18:13     MarkDuplicatesWithMateCigar     Marking 54595945 records as duplicates.
    INFO    2016-03-22 10:18:13     MarkDuplicatesWithMateCigar     Found 15988109 optical duplicate clusters.

I think to actually compare this tool, I'll need to run it on a Loeb sample, but for now I just want to show how much better it is than the TruSeq collapse using barcodes.

I'll throw that on the to do list, probably for tomorrow.

Here is the read counts before and after MarkDuplicatesWithMateCigar

    samtools view -c 01_100Colo829_TS16N_noBS_MCtag_RMdupms.bam
    6783276
    samtools view -c 01_100Colo829_TS16N_noBS_MCtag.sort.bam
    61379221

Using the same coverage calculation as above, we get an expected per base depth of coverage in this sample of

    (6783276*133)/28787 = 31339.69

That is unexpected.  I thought that this tool would be more agressive about duplicate removal, but that appears to be roughtly the same number we observed from the BMFtools demultiplexing.  This suggests I *NEED* to run MarkDuplicatesWithMateCigar on a Loeb sample for comparison.  *edit: Damn. Wait, that includes, fails and off target reads.  I need to filter these.  I'll use GATK's Depth of Coverage first.*  Command line:

    java -Xmx15G -jar ~/bin/GenomeAnalysisTK.jar \
        -T DepthOfCoverage \
        -R /uufs/chpc.utah.edu/common/home/arup-storage3/Reference/Installation/resources/usr/dbs/human_g1k_v37.fasta
        -o GATK_DoC/01_100Colo829_TS16N_noBS_MCtag_RMdupms \
        -I 01_100Colo829_TS16N_noBS_MCtag_RMdupms.bam \
        -L /uufs/chpc.utah.edu/common/home/arup-storage1/u0521163/Panel_Development/ctDNA_V2_probes_with_colo829_dopes.bed

run finished quickly.  I guesss the BAM is small.  There were much fewer reads failing the QC and unmapped filter than I expected.

    INFO  10:55:48,552 MicroScheduler - 23439 reads were filtered out during the traversal out of approximately 537436 total reads (4.36%)
    INFO  10:55:48,553 MicroScheduler -   -> 0 reads (0.00% of total) failing BadCigarFilter
    INFO  10:55:48,553 MicroScheduler -   -> 0 reads (0.00% of total) failing DuplicateReadFilter
    INFO  10:55:48,553 MicroScheduler -   -> 0 reads (0.00% of total) failing FailsVendorQualityCheckFilter
    INFO  10:55:48,553 MicroScheduler -   -> 0 reads (0.00% of total) failing MalformedReadFilter
    INFO  10:55:48,553 MicroScheduler -   -> 0 reads (0.00% of total) failing NotPrimaryAlignmentFilter
    INFO  10:55:48,553 MicroScheduler -   -> 23439 reads (4.36% of total) failing UnmappedReadFilter

Okay, big difference here.  They find only 537436 reads, much different than what we saw using "samtools view -c", huh. Oh, of course that includes off target reads as well, so, blah.

Wow.  **The depth of coverage after MarkDuplicateWithMateCigar is 1577.90** for the TrueSeq sample.  This compares to the **depth of coverage after BMF collapse of 1468.46**.   This convincingly shows that this method is doing a better job collapsing reads than the barcodes based method for the TruSeq data.  That's it, nail in the coffin for the TruSeq.  I will still run a Loeb sample to allow for that comparison, but honestly, this method looks really, really good.

##MarkDuplicatesWithMateCigar on cutadapt'd Loeb data (HiSeq_Loeb_Run2)
    /uufs/chpc.utah.edu/common/home/arup-storage1/u0521163/ctDNA_Data/no_barcodes/Loeb

first to cutadapt the fastqs prior to alignment (I will also use these in a BMFtools run, see how that changes the meta-stats):

    cutadapt \
        --mask-adapter \
        -O 6 \
        -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC \
        -g ACACTCTTTCCCTACACGACGCTCTTCCGATCT \
        -A AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC \
        -G ACACTCTTTCCCTACACGACGCTCTTCCGATCT \
        -o 5_100Colo_10N11N_LB.ca.R1.fq.gz \
        -p 5_100Colo_10N11N_LB.ca.R2.fq.gz \
        5_100Colo_10N11N_LB_GACACAGT-GACACAGT_cat_R1.fastq.gz \
        5_100Colo_10N11N_LB_GACACAGT-GACACAGT_cat_R2.fastq.gz

Cutadapt has been running for more than 4 hours on this data, it's probably not feasable to use cutadapt upstream of demultiplexing the barcoded reads, at least not for Loeb data.  Unless we throw it in the mark-split step and parallelize the run.

##Merged paired alignments, reconsidering pandaseq?

I should talk to Daniel a bit about this, and see what happened to the MPA stuff.  Did that get dumped out of the repo?

There are a few big questions about this tech
+ Does using pandaseq or other MPA programs break downstream compatibility?
+ Does it hurt the ability of variant callers like haplotype caller to use the paired data for assembly?
+ How much time does this add to our analysis pipeline?

Right now I've installed pandaseq and am going to glance through the usage.

#Running to do list
+ Add MuTect2 into Loeb Snakemake workflow
+ Check MuTect2 output for 100% Tumor Colo Sample, and create ROC curve.
    + Work on code to generate the FM/FP plots.
    + Create code to generate ROC curves overall
+ Work on GCC on the Slurm cluster
+ Run cutadapt prior to barcode collapse with BMFtools, and compare to run where cutadapt comes after collapse.
+ Look into PandaSeq or similar, how could/should we utilize overlapping reads?
+ Run MarkDuplicatesWithMateCigar on Loeb data, preferably the 100% tumor, same as the TruSeq run.  Be sure ot use a sample that is run through cutadapt first.
+ Run translocation pipeline on the ctDNA sample
+ Create analysis snakemake workflow
